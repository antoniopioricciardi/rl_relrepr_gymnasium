{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/antonioricciardi/projects/rl_relrepr_gymnasium'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â change working directory to the root of the project\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "test_path = 'experiments/stitching_tests'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'experiments/stitching_tests/LunarLanderRGB/rgb/absolute/LunarLanderRGB_relu_stitching_results_ppo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     exp_path \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_id_encoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_relu_stitching_results_ppo.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# read stitching_results_relative_ppo with pandas\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv(f'{test_path}/{env_id}/{env_info}/{mode}/{env_id_encoder}_relu_stitching_results_ppo.csv', sep=',')\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m df\u001b[38;5;241m.\u001b[39mtail()\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'experiments/stitching_tests/LunarLanderRGB/rgb/absolute/LunarLanderRGB_relu_stitching_results_ppo.csv'"
     ]
    }
   ],
   "source": [
    "env_id = \"LunarLanderRGB\" # \"CarRacing-v2\"\n",
    "env_id_encoder = \"LunarLanderRGB\" # \"CarRacing-v2\"\n",
    "env_info = \"rgb\"\n",
    "mode = \"absolute\" #Â \"absolute\"\n",
    "anc_alpha = \"-1\"\n",
    "\n",
    "\"\"\" SHOW LOGGED DATA \"\"\"\n",
    "exp_path = f'{test_path}/{env_id}/{env_info}/{mode}/'\n",
    "if mode == \"relative\":\n",
    "    exp_path += f'a_{anc_alpha}/{env_id_encoder}_relu_stitching_results_ppo.csv'\n",
    "else:\n",
    "    exp_path += f'{env_id_encoder}_relu_stitching_results_ppo.csv'\n",
    "# read stitching_results_relative_ppo with pandas\n",
    "# df = pd.read_csv(f'{test_path}/{env_id}/{env_info}/{mode}/{env_id_encoder}_relu_stitching_results_ppo.csv', sep=',')\n",
    "df = pd.read_csv(exp_path, sep=',')\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "file has the following columns:\n",
    "track_seed,encoder_background,policy_background,score,max_score_reached,episode_length,algorithm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Env Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/stitching_tests/LunarLanderRGB-3/rgb/absolute/LunarLanderRGB-3_relu_stitching_results_ppo.csv \n",
      "\n",
      "295.0615539550781\n",
      "295.0615539550781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_66596/4054249583.py:42: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']})\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "env_id_encoder = \"LunarLanderRGB-3\" # \"CarRacing-v2\"\n",
    "env_id = \"LunarLanderRGB-3\" # \"CarRacing-v2\"\n",
    "# encoder_order = ['green', 'red', 'blue'] if env_id_encoder.startswith(\"CarRacing-v2\") else ['plain', 'green', 'red']\n",
    "encoder_order = ['green', 'red', 'blue'] if env_id_encoder.startswith(\"CarRacing-v2\") else ['white', 'red']\n",
    "if env_id.endswith(\"multicolor\"):\n",
    "    encoder_order = ['multicolor']\n",
    "stitching_methods = [\"absolute\", \"relative\", \"translate\"]\n",
    "stitching_method = stitching_methods[0]\n",
    "anchoring_method = \"random\"\n",
    "anchors_alpha = -1 # 0.999# -1\n",
    "\n",
    "a_alpha = str(anchors_alpha)\n",
    "\n",
    "model_activation = \"relu\"\n",
    "model_algo = \"ppo\"\n",
    "\n",
    "\n",
    "stitch_filename = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename += f\"{anchoring_method}/\"\n",
    "if stitching_method == \"relative\":\n",
    "    stitch_filename += f\"a_{a_alpha}/\"\n",
    "stitch_filename += f\"{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "\n",
    "#Â stitch_filename = \"experiments/stitching_tests/CarRacing-v2-multicolor/rgb/absolute/yellow-bg_CarRacing-v2_relu_stitching_results_ppo.csv\"\n",
    "\n",
    "print(stitch_filename, \"\\n\")\n",
    "\n",
    "df = pd.read_csv(stitch_filename)\n",
    "\n",
    "# Convert 'encoder_background' to categorical with specified order\n",
    "df['encoder_background'] = pd.Categorical(df['encoder_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# Convert 'policy_background' to categorical with specified order\n",
    "df['policy_background'] = pd.Categorical(df['policy_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std']})\n",
    "# show another column \"score\" next to max_score columnm containing the mean and std of the score\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std'], 'score': ['mean', 'std']})\n",
    "\n",
    "df.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']})\n",
    "\n",
    "print(df['score'].max())\n",
    "# clamp negative score so that they are never below (- maximum score)\n",
    "max_score = df['score'].max()\n",
    "df['score'] = df['score'].apply(lambda x: max(-max_score, x))\n",
    "print(df['score'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_seed</th>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th>encoder_seed</th>\n",
       "      <th>policy_seed</th>\n",
       "      <th>encoder_env</th>\n",
       "      <th>policy_env</th>\n",
       "      <th>score</th>\n",
       "      <th>episode_length</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clustering_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [env_seed, encoder_background, policy_background, encoder_seed, policy_seed, encoder_env, policy_env, score, episode_length, algorithm, clustering_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get encoder seed and policy seed that have top average score for encoder_background=green and policy_background=red\n",
    "df[(df['encoder_background'] == 'green') & (df['policy_background'] == 'red')].sort_values(by='score', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_seed</th>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th>encoder_seed</th>\n",
       "      <th>policy_seed</th>\n",
       "      <th>encoder_env</th>\n",
       "      <th>policy_env</th>\n",
       "      <th>score</th>\n",
       "      <th>episode_length</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clustering_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [env_seed, encoder_background, policy_background, encoder_seed, policy_seed, encoder_env, policy_env, score, episode_length, algorithm, clustering_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['encoder_background'] == 'green') & (df['policy_background'] == 'red')].sort_values(by='score', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 160\n"
     ]
    }
   ],
   "source": [
    "# print the total number of rows\n",
    "print(f\"Total number of rows: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same encoder and policy background\n",
      "-177.22056362628936\n",
      "207.86474054590192\n",
      "\n",
      "Different encoder and policy background\n",
      "nan\n",
      "nan\n",
      "Cumulative scores\n",
      "-177.22056362628936\n",
      "207.86474054590192\n",
      "Same encoder and policy seed\n",
      "142.486137008667\n",
      "168.00612716244098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_66596/2909045596.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  equal_seed_scores = equal_seed.groupby(['encoder_seed', 'policy_seed', 'encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">white</th>\n",
       "      <th>white</th>\n",
       "      <td>124.923343</td>\n",
       "      <td>180.750819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>139.343113</td>\n",
       "      <td>167.101164</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>186.205985</td>\n",
       "      <td>165.337667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>119.472107</td>\n",
       "      <td>176.965304</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean_score   std_score seed\n",
       "encoder_background policy_background                             \n",
       "white              white              124.923343  180.750819    1\n",
       "                   white              139.343113  167.101164    2\n",
       "                   white              186.205985  165.337667    3\n",
       "                   white              119.472107  176.965304    4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the mean score of all the experiments where encoder_background == policy_background\n",
    "# compute the mean score\n",
    "print('Same encoder and policy background')\n",
    "print(df[df['encoder_background'] == df['policy_background']]['score'].mean())\n",
    "print(df[df['encoder_background'] == df['policy_background']]['score'].std())\n",
    "print()\n",
    "# show the mean score of all the experiments, excluding where encoder_background == policy_background\n",
    "# compute the mean score\n",
    "print('Different encoder and policy background')\n",
    "print(df[df['encoder_background'] != df['policy_background']]['score'].mean())\n",
    "print(df[df['encoder_background'] != df['policy_background']]['score'].std())\n",
    "\n",
    "print('Cumulative scores')\n",
    "print(df['score'].mean())\n",
    "print(df['score'].std())\n",
    "\n",
    "#Â get scores for when encoder_seed == policy_seed and encoder_background == policy_background\n",
    "print('Same encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].std())\n",
    "\n",
    "# get all the rows where encoder_seed == policy_seed and encoder_background == policy_background\n",
    "equal_seed = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]\n",
    "# compute aggregate score over environment seeds, show mean and std, encoder_seed and policy_seed, encoder_background and policy_background only for values that are the not nan\n",
    "equal_seed_scores = equal_seed.groupby(['encoder_seed', 'policy_seed', 'encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
    "# rename mean score column to mean_score\n",
    "equal_seed_scores.columns = ['mean_score', 'std_score']\n",
    "# aggregate encoder_seed and policy_seed into one column called seed\n",
    "equal_seed_scores['seed'] = equal_seed_scores.index.get_level_values('encoder_seed').astype(str)\n",
    "# disaggregate encoder_seed and policy_seed, preserve encoder_background and policy_background\n",
    "equal_seed_scores.index = equal_seed_scores.index.droplevel(['encoder_seed', 'policy_seed'])\n",
    "# compute mean and std over seeds\n",
    "\n",
    "equal_seed_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When encoder seed and policy seed are different, or when the encoder and policy background are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_66596/749558234.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  diff_scores = equal_seed.groupby(['encoder_seed', 'policy_seed', 'encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_66596/749558234.py:14: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  diff_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': ['mean', 'std']})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">white</th>\n",
       "      <th>white</th>\n",
       "      <td>-283.789464</td>\n",
       "      <td>20.863769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">red</th>\n",
       "      <th>white</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean_score           \n",
       "                                            mean        std\n",
       "encoder_background policy_background                       \n",
       "white              white             -283.789464  20.863769\n",
       "                   red                       NaN        NaN\n",
       "red                white                     NaN        NaN\n",
       "                   red                       NaN        NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" STITCHING \"\"\"\n",
    "# get all the rows where encoder_seed != policy_seed or encoder_background != policy_background\n",
    "equal_seed = df[(df['encoder_seed'] != df['policy_seed']) | (df['encoder_background'] != df['policy_background'])]\n",
    "# compute aggregate score over environment seeds, show mean and std, encoder_seed and policy_seed, encoder_background and policy_background only for values that are the not nan\n",
    "diff_scores = equal_seed.groupby(['encoder_seed', 'policy_seed', 'encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
    "# rename mean score column to mean_score\n",
    "diff_scores.columns = ['mean_score', 'std_score']\n",
    "# aggregate encoder_seed and policy_seed into one column called seed\n",
    "diff_scores['seed'] = diff_scores.index.get_level_values('encoder_seed').astype(str)\n",
    "# disaggregate encoder_seed and policy_seed, preserve encoder_background and policy_background\n",
    "diff_scores.index = diff_scores.index.droplevel(['encoder_seed', 'policy_seed'])\n",
    "# compute mean and std over seeds\n",
    "\n",
    "diff_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': ['mean', 'std']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute mean scores over different seeds for when encoder_background and policy_background are the same, and the seed too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_66596/703665784.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  average_scores = equal_background_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': 'mean', 'std_score': 'std'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">white</th>\n",
       "      <th>white</th>\n",
       "      <td>142.486137</td>\n",
       "      <td>7.493451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">red</th>\n",
       "      <th>white</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean_score  std_score\n",
       "encoder_background policy_background                       \n",
       "white              white              142.486137   7.493451\n",
       "                   red                       NaN        NaN\n",
       "red                white                     NaN        NaN\n",
       "                   red                       NaN        NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" NO STITCHING \"\"\"\n",
    "equal_background_scores = equal_seed_scores[equal_seed_scores.index.get_level_values('encoder_background') == equal_seed_scores.index.get_level_values('policy_background')]\n",
    "average_scores = equal_background_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': 'mean', 'std_score': 'std'})\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_66596/790856185.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  median_scores = equal_background_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': 'median', 'std_score': 'std'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">white</th>\n",
       "      <th>white</th>\n",
       "      <td>132.133228</td>\n",
       "      <td>7.493451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">red</th>\n",
       "      <th>white</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean_score  std_score\n",
       "encoder_background policy_background                       \n",
       "white              white              132.133228   7.493451\n",
       "                   red                       NaN        NaN\n",
       "red                white                     NaN        NaN\n",
       "                   red                       NaN        NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_scores = equal_background_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': 'median', 'std_score': 'std'})\n",
    "median_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get maximum scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_66596/128057864.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  idxmax_list = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])].groupby(['encoder_background']).agg({'score': ['max', 'mean', 'std', 'idxmax']})['score']['idxmax'].tolist()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't get idxmax of an empty group due to unobserved categories. Specify observed=True in groupby instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save idxmax to a list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m idxmax_list \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoder_seed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpolicy_seed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoder_background\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpolicy_background\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoder_background\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midxmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(idxmax_list)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Â select encoder_background, policy_background, seeds from the list\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1432\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m   1431\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m-> 1432\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/apply.py:190\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/apply.py:423\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    416\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1608\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1603\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine_kwargs})\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[1;32m   1606\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1607\u001b[0m ):\n\u001b[0;32m-> 1608\u001b[0m     result_index, result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1611\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/apply.py:496\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[0;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m key_data\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), op_name)(how, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/apply.py:497\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    493\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m key_data\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 497\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:257\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m    256\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m--> 257\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:362\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[1;32m    361\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[0;32m--> 362\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:249\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1186\u001b[0m, in \u001b[0;36mSeriesGroupBy.idxmax\u001b[0;34m(self, axis, skipna)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;129m@doc\u001b[39m(Series\u001b[38;5;241m.\u001b[39midxmax\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m)\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21midxmax\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m, axis: Axis \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default, skipna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_idxmax_idxmin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43midxmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:5856\u001b[0m, in \u001b[0;36mGroupBy._idxmax_idxmin\u001b[0;34m(self, how, ignore_unobserved, axis, skipna, numeric_only)\u001b[0m\n\u001b[1;32m   5853\u001b[0m         raise_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   5855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_err:\n\u001b[0;32m-> 5856\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5857\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of an empty group due to unobserved categories. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5858\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecify observed=True in groupby instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5859\u001b[0m         )\n\u001b[1;32m   5860\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skipna:\n\u001b[1;32m   5861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mValueError\u001b[0m: Can't get idxmax of an empty group due to unobserved categories. Specify observed=True in groupby instead."
     ]
    }
   ],
   "source": [
    "# save idxmax to a list\n",
    "idxmax_list = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])].groupby(['encoder_background']).agg({'score': ['max', 'mean', 'std', 'idxmax']})['score']['idxmax'].tolist()\n",
    "print(idxmax_list)\n",
    "#Â select encoder_background, policy_background, seeds from the list\n",
    "selection = df.iloc[idxmax_list][['encoder_background', 'policy_background', 'encoder_seed', 'policy_seed', 'score']]\n",
    "selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get minimum scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â get minimum score\n",
    "min_score = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].min()\n",
    "#Â get the row with the minimum score\n",
    "min_score_row = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background']) & (df['score'] == min_score)]\n",
    "min_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Â get maximum score\n",
    "max_score = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].max()\n",
    "#Â get the row with the maximum score\n",
    "max_score_row = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background']) & (df['score'] == max_score)]\n",
    "max_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarRacing multicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "background = \"multicolor\"\n",
    "env_id_encoder = \"CarRacing-v2-multicolor\"\n",
    "env_id = \"CarRacing-v2\"\n",
    "encoder_order = ['multicolor'] if env_id_encoder.startswith(\"CarRacing-v2\") else ['plain', 'green', 'red']\n",
    "controller_order = ['green', 'red', 'blue'] if env_id_encoder.startswith(\"CarRacing-v2\") else ['plain', 'green', 'red']\n",
    "stitching_methods = [\"absolute\", \"relative\", \"translate\"]\n",
    "stitching_method = stitching_methods[0]\n",
    "anchoring_method = \"fps\"\n",
    "anchors_alpha = 0.999\n",
    "\n",
    "a_alpha = str(anchors_alpha)\n",
    "\n",
    "model_activation = \"relu\"\n",
    "model_algo = \"ppo\"\n",
    "\n",
    "\n",
    "stitch_filename = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename += f\"{anchoring_method}/\"\n",
    "if stitching_method == \"relative\":\n",
    "    stitch_filename += f\"a_{a_alpha}/\"\n",
    "# stitch_filename += f\"{background}-bg_{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "stitch_filename += f\"{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "\n",
    "df = pd.read_csv(stitch_filename)\n",
    "\n",
    "# Convert 'encoder_background' to categorical with specified order\n",
    "df['encoder_background'] = pd.Categorical(df['encoder_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# Convert 'policy_background' to categorical with specified order\n",
    "df['policy_background'] = pd.Categorical(df['policy_background'], categories=controller_order, ordered=True)\n",
    "\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std']})\n",
    "# show another column \"score\" next to max_score columnm containing the mean and std of the score\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std'], 'score': ['mean', 'std']})\n",
    "\n",
    "df.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results when encoder_seed and policy_seed are the same\n",
    "print('Same encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] == df['policy_seed'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] == df['policy_seed'])]['score'].std())\n",
    "\n",
    "# print results when encoder_seed and policy_seed are different\n",
    "print('Different encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] != df['policy_seed'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] != df['policy_seed'])]['score'].std())\n",
    "\n",
    "# print cumulative results\n",
    "print('Cumulative scores')\n",
    "print(df['score'].mean())\n",
    "print(df['score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "env_id = \"BoxingNoFrameskip-v4\"\n",
    "env_id_encoder = \"BoxingNoFrameskip-v4\"\n",
    "encoder_order = ['plain', 'green', 'red']\n",
    "stitching_methods = [\"absolute\", \"relative\", \"translate\"]\n",
    "stitching_method = stitching_methods[2]\n",
    "anchoring_method = \"fps\"\n",
    "\n",
    "anchors_alpha = 0.999\n",
    "\n",
    "a_alpha = str(anchors_alpha)\n",
    "\n",
    "model_activation = \"relu\"\n",
    "model_algo = \"ppo\"\n",
    "\n",
    "stitch_filename = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename += f\"{anchoring_method}/\"\n",
    "if stitching_method == \"relative\":\n",
    "    stitch_filename += f\"a_{a_alpha}/\"\n",
    "stitch_filename += f\"{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "\n",
    "df = pd.read_csv(stitch_filename)\n",
    "\n",
    "# Convert 'encoder_background' to categorical with specified order\n",
    "df['encoder_background'] = pd.Categorical(df['encoder_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# Convert 'policy_background' to categorical with specified order\n",
    "df['policy_background'] = pd.Categorical(df['policy_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std']})\n",
    "# show another column \"score\" next to max_score columnm containing the mean and std of the score\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std'], 'score': ['mean', 'std']})\n",
    "\n",
    "df.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the dataframe where encoder_background == policy_background and encoder_background == 'plain'. Show the score, encoder_seed and policy_seed\n",
    "df[(df['policy_background'] == 'plain') & (df['encoder_background'] == 'plain')][['score', 'encoder_background', 'policy_background', 'encoder_seed', 'policy_seed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the total number of rows\n",
    "print(f\"Total number of rows: {df.shape[0]}\")\n",
    "\n",
    "#Â get scores for when encoder_seed == policy_seed and encoder_background == policy_background\n",
    "print('Same encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].std())\n",
    "\n",
    "# show the mean score of all the experiments where encoder_background == policy_background\n",
    "# compute the mean score\n",
    "print('Same encoder and policy background')\n",
    "print(df[df['encoder_background'] == df['policy_background']]['score'].mean())\n",
    "print(df[df['encoder_background'] == df['policy_background']]['score'].std())\n",
    "print()\n",
    "# show the mean score of all the experiments, excluding where encoder_background == policy_background\n",
    "# compute the mean score\n",
    "print('Different encoder and policy background')\n",
    "print(df[df['encoder_background'] != df['policy_background']]['score'].mean())\n",
    "print(df[df['encoder_background'] != df['policy_background']]['score'].std())\n",
    "\n",
    "print('Cumulative scores')\n",
    "print(df['score'].mean())\n",
    "print(df['score'].std())\n",
    "\n",
    "#Â get scores for when encoder_seed == policy_seed and encoder_background == policy_background\n",
    "print('Same encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].std())\n",
    "\n",
    "# get all the rows where encoder_seed == policy_seed and encoder_background == policy_background\n",
    "equal_seed = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]\n",
    "# compute mean score over colors, show mean and std, encoder_seed and policy_seed, encoder_background and policy_background only for values that are the not nan\n",
    "equal_seed_scores = equal_seed.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
    "equal_seed_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When encoder seed and policy seed are different, or when the encoder and policy background are different (in which case we do not care whether the seed is the same or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the rows where encoder_seed != policy_seed or encoder_background != policy_background\n",
    "diff = df[(df['encoder_seed'] != df['policy_seed']) | (df['encoder_background'] != df['policy_background'])]\n",
    "# compute aggregate score over environment seeds, show mean and std, encoder_seed and policy_seed, encoder_background and policy_background only for values that are the not nan\n",
    "diff_scores = diff.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
    "diff_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CarRacing-v2\"\n",
    "env_info = \"rgb\"\n",
    "anchoring_method = \"fps\"\n",
    "\n",
    "\"\"\" SHOW LOGGED DATA \"\"\"\n",
    "\n",
    "# read stitching_results_relative_ppo with pandas\n",
    "df1 = pd.read_csv(f'{test_path}/{env_id}/{env_info}/absolute/relu_stitching_results_ppo.csv', sep=',')\n",
    "df1.head()\n",
    "stitch_filename_2 = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename_2 += f\"{anchoring_method}/\"\n",
    "stitch_filename_2 += f\"{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "# df2 = pd.read_csv(f'{test_path}/{env_id}/{env_info}/translate/relu_stitching_results_ppo.csv', sep=',')\n",
    "df2 = pd.read_csv(stitch_filename_2)\n",
    "\n",
    "\n",
    "\n",
    "# join the two dataframes adding a new column called \"method\". Use \"absolute\" under method for df1 and \"translate\" for df2\n",
    "df1['method'] = 'absolute'\n",
    "# sum 40 to df1 env_seed column\n",
    "df1['env_seed'] = df1['env_seed'] + 39\n",
    "df2['method'] = 'translate'\n",
    "\n",
    "#Â create df3 containing data where encoder_background and policy_background are the same, and remove it from df1 and df2\n",
    "df3 = df1[df1['encoder_background'] == df1['policy_background']]\n",
    "df3['method'] = 'absolute_original'\n",
    "df1 = df1[df1['encoder_background'] != df1['policy_background']]\n",
    "df4 = df2[df2['encoder_background'] == df2['policy_background']]\n",
    "df4['method'] = 'translate_original'\n",
    "df2 = df2[df2['encoder_background'] != df2['policy_background']]\n",
    "\n",
    "# concatenate the four dataframes\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\"\"\" df contains the following columns: env_seed\tencoder_background\tpolicy_background\tscore\tmax_score_reached\tepisode_length\talgorithm\n",
    "Create a histogram with x axis being the env_seed and y axis being the score. Use \"absolute\" and \"translation\" as colors.\n",
    "Each score must be a bar.\n",
    "\"\"\"\n",
    "fig = px.box(df, x=\"env_seed\", y=\"score\", color=\"method\", facet_row=\"encoder_background\", height=800)\n",
    "#fig = px.histogram(df, x=\"env_seed\", y=\"score\", color=\"method\", barmode=\"group\", histfunc=\"avg\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Allora puoi fare un istrogramma con plotly express. Prendi in input il df e metti come x il track_seed,\n",
    "come y il valore di score raggiunto o quello che Ã¨, come color il metodo usato (che sarÃ  o absolute o translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
