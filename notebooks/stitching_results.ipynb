{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/antonioricciardi/projects/rl_relrepr_gymnasium'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory to the root of the project\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "test_path = 'experiments/stitching_tests'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_seed</th>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th>encoder_seed</th>\n",
       "      <th>policy_seed</th>\n",
       "      <th>encoder_env</th>\n",
       "      <th>policy_env</th>\n",
       "      <th>score</th>\n",
       "      <th>episode_length</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clustering_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>-93.629555</td>\n",
       "      <td>999.0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>878.161255</td>\n",
       "      <td>999.0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>878.161255</td>\n",
       "      <td>999.0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>878.161255</td>\n",
       "      <td>999.0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>CarRacing-v2</td>\n",
       "      <td>878.161255</td>\n",
       "      <td>999.0</td>\n",
       "      <td>ppo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    env_seed encoder_background policy_background  encoder_seed  policy_seed  \\\n",
       "59         4         multicolor        multicolor             4            3   \n",
       "60         1         multicolor        multicolor             4            4   \n",
       "61         2         multicolor        multicolor             4            4   \n",
       "62         3         multicolor        multicolor             4            4   \n",
       "63         4         multicolor        multicolor             4            4   \n",
       "\n",
       "     encoder_env    policy_env       score  episode_length algorithm  \\\n",
       "59  CarRacing-v2  CarRacing-v2  -93.629555           999.0       ppo   \n",
       "60  CarRacing-v2  CarRacing-v2  878.161255           999.0       ppo   \n",
       "61  CarRacing-v2  CarRacing-v2  878.161255           999.0       ppo   \n",
       "62  CarRacing-v2  CarRacing-v2  878.161255           999.0       ppo   \n",
       "63  CarRacing-v2  CarRacing-v2  878.161255           999.0       ppo   \n",
       "\n",
       "    clustering_time  \n",
       "59                0  \n",
       "60                0  \n",
       "61                0  \n",
       "62                0  \n",
       "63                0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_id = \"CarRacing-v2-multicolor\"\n",
    "env_id_encoder = \"CarRacing-v2\"\n",
    "env_info = \"rgb\"\n",
    "\n",
    "\"\"\" SHOW LOGGED DATA \"\"\"\n",
    "\n",
    "# read stitching_results_relative_ppo with pandas\n",
    "df = pd.read_csv(f'{test_path}/{env_id}/{env_info}/absolute/{env_id_encoder}_relu_stitching_results_ppo.csv', sep=',')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile has the following columns:\\ntrack_seed,encoder_background,policy_background,score,max_score_reached,episode_length,algorithm\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "file has the following columns:\n",
    "track_seed,encoder_background,policy_background,score,max_score_reached,episode_length,algorithm\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarRacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/stitching_tests/CarRacing-v2-multicolor/rgb/absolute/green-bg_CarRacing-v2_relu_stitching_results_ppo.csv \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_7897/676842021.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multicolor</th>\n",
       "      <th>multicolor</th>\n",
       "      <td>159.702141</td>\n",
       "      <td>400.574593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           score            \n",
       "                                            mean         std\n",
       "encoder_background policy_background                        \n",
       "multicolor         multicolor         159.702141  400.574593"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "env_id_encoder = \"CarRacing-v2\"\n",
    "env_id = \"CarRacing-v2-multicolor\"\n",
    "encoder_order = ['green', 'red', 'blue'] if env_id_encoder.startswith(\"CarRacing-v2\") else ['plain', 'green', 'red']\n",
    "if env_id.endswith(\"multicolor\"):\n",
    "    encoder_order = ['multicolor']\n",
    "stitching_methods = [\"absolute\", \"relative\", \"translate\"]\n",
    "stitching_method = stitching_methods[0]\n",
    "anchoring_method = \"fps\"\n",
    "anchors_alpha = 0.999\n",
    "\n",
    "a_alpha = str(anchors_alpha)\n",
    "\n",
    "model_activation = \"relu\"\n",
    "model_algo = \"ppo\"\n",
    "\n",
    "\n",
    "stitch_filename = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename += f\"{anchoring_method}/\"\n",
    "if stitching_method == \"relative\":\n",
    "    stitch_filename += f\"a_{a_alpha}/\"\n",
    "stitch_filename += f\"{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "\n",
    "stitch_filename = \"experiments/stitching_tests/CarRacing-v2-multicolor/rgb/absolute/green-bg_CarRacing-v2_relu_stitching_results_ppo.csv\"\n",
    "\n",
    "print(stitch_filename, \"\\n\")\n",
    "\n",
    "df = pd.read_csv(stitch_filename)\n",
    "\n",
    "# Convert 'encoder_background' to categorical with specified order\n",
    "df['encoder_background'] = pd.Categorical(df['encoder_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# Convert 'policy_background' to categorical with specified order\n",
    "df['policy_background'] = pd.Categorical(df['policy_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std']})\n",
    "# show another column \"score\" next to max_score columnm containing the mean and std of the score\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std'], 'score': ['mean', 'std']})\n",
    "\n",
    "df.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_seed</th>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th>encoder_seed</th>\n",
       "      <th>policy_seed</th>\n",
       "      <th>encoder_env</th>\n",
       "      <th>policy_env</th>\n",
       "      <th>score</th>\n",
       "      <th>episode_length</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clustering_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [env_seed, encoder_background, policy_background, encoder_seed, policy_seed, encoder_env, policy_env, score, episode_length, algorithm, clustering_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get encoder seed and policy seed that have top average score for encoder_background=green and policy_background=red\n",
    "df[(df['encoder_background'] == 'green') & (df['policy_background'] == 'red')].sort_values(by='score', ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>env_seed</th>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th>encoder_seed</th>\n",
       "      <th>policy_seed</th>\n",
       "      <th>encoder_env</th>\n",
       "      <th>policy_env</th>\n",
       "      <th>score</th>\n",
       "      <th>episode_length</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>clustering_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [env_seed, encoder_background, policy_background, encoder_seed, policy_seed, encoder_env, policy_env, score, episode_length, algorithm, clustering_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['encoder_background'] == 'green') & (df['policy_background'] == 'red')].sort_values(by='score', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 64\n"
     ]
    }
   ],
   "source": [
    "# print the total number of rows\n",
    "print(f\"Total number of rows: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same encoder and policy background\n",
      "159.7021405994892\n",
      "400.57459315099624\n",
      "\n",
      "Different encoder and policy background\n",
      "nan\n",
      "nan\n",
      "Cumulative scores\n",
      "159.7021405994892\n",
      "400.57459315099624\n",
      "Same encoder and policy seed\n",
      "845.2463531494141\n",
      "24.709410023336787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_7897/2909045596.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  equal_seed_scores = equal_seed.groupby(['encoder_seed', 'policy_seed', 'encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">multicolor</th>\n",
       "      <th>multicolor</th>\n",
       "      <td>831.140076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multicolor</th>\n",
       "      <td>815.466553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multicolor</th>\n",
       "      <td>856.217529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multicolor</th>\n",
       "      <td>878.161255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean_score  std_score seed\n",
       "encoder_background policy_background                            \n",
       "multicolor         multicolor         831.140076        0.0    1\n",
       "                   multicolor         815.466553        0.0    2\n",
       "                   multicolor         856.217529        0.0    3\n",
       "                   multicolor         878.161255        0.0    4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the mean score of all the experiments where encoder_background == policy_background\n",
    "# compute the mean score\n",
    "print('Same encoder and policy background')\n",
    "print(df[df['encoder_background'] == df['policy_background']]['score'].mean())\n",
    "print(df[df['encoder_background'] == df['policy_background']]['score'].std())\n",
    "print()\n",
    "# show the mean score of all the experiments, excluding where encoder_background == policy_background\n",
    "# compute the mean score\n",
    "print('Different encoder and policy background')\n",
    "print(df[df['encoder_background'] != df['policy_background']]['score'].mean())\n",
    "print(df[df['encoder_background'] != df['policy_background']]['score'].std())\n",
    "\n",
    "print('Cumulative scores')\n",
    "print(df['score'].mean())\n",
    "print(df['score'].std())\n",
    "\n",
    "# get scores for when encoder_seed == policy_seed and encoder_background == policy_background\n",
    "print('Same encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].std())\n",
    "\n",
    "# get all the rows where encoder_seed == policy_seed and encoder_background == policy_background\n",
    "equal_seed = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]\n",
    "# compute aggregate score over environment seeds, show mean and std, encoder_seed and policy_seed, encoder_background and policy_background only for values that are the not nan\n",
    "equal_seed_scores = equal_seed.groupby(['encoder_seed', 'policy_seed', 'encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
    "# rename mean score column to mean_score\n",
    "equal_seed_scores.columns = ['mean_score', 'std_score']\n",
    "# aggregate encoder_seed and policy_seed into one column called seed\n",
    "equal_seed_scores['seed'] = equal_seed_scores.index.get_level_values('encoder_seed').astype(str)\n",
    "# disaggregate encoder_seed and policy_seed, preserve encoder_background and policy_background\n",
    "equal_seed_scores.index = equal_seed_scores.index.droplevel(['encoder_seed', 'policy_seed'])\n",
    "# compute mean and std over seeds\n",
    "\n",
    "equal_seed_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When encoder seed and policy seed are different, or when the encoder and policy background are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_7897/2418010615.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  diff_scores = equal_seed.groupby(['encoder_seed', 'policy_seed', 'encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_7897/2418010615.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  diff_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': ['mean', 'std']})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multicolor</th>\n",
       "      <th>multicolor</th>\n",
       "      <td>-68.812597</td>\n",
       "      <td>40.948082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean_score           \n",
       "                                           mean        std\n",
       "encoder_background policy_background                      \n",
       "multicolor         multicolor        -68.812597  40.948082"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the rows where encoder_seed != policy_seed or encoder_background != policy_background\n",
    "equal_seed = df[(df['encoder_seed'] != df['policy_seed']) | (df['encoder_background'] != df['policy_background'])]\n",
    "# compute aggregate score over environment seeds, show mean and std, encoder_seed and policy_seed, encoder_background and policy_background only for values that are the not nan\n",
    "diff_scores = equal_seed.groupby(['encoder_seed', 'policy_seed', 'encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
    "# rename mean score column to mean_score\n",
    "diff_scores.columns = ['mean_score', 'std_score']\n",
    "# aggregate encoder_seed and policy_seed into one column called seed\n",
    "diff_scores['seed'] = diff_scores.index.get_level_values('encoder_seed').astype(str)\n",
    "# disaggregate encoder_seed and policy_seed, preserve encoder_background and policy_background\n",
    "diff_scores.index = diff_scores.index.droplevel(['encoder_seed', 'policy_seed'])\n",
    "# compute mean and std over seeds\n",
    "\n",
    "diff_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': ['mean', 'std']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute mean scores over different seeds for when encoder_background and policy_background are the same, and the seed too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_7897/2295913214.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  average_scores = equal_background_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': 'mean', 'std_score': 'std'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multicolor</th>\n",
       "      <th>multicolor</th>\n",
       "      <td>845.246353</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean_score  std_score\n",
       "encoder_background policy_background                       \n",
       "multicolor         multicolor         845.246353        0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_background_scores = equal_seed_scores[equal_seed_scores.index.get_level_values('encoder_background') == equal_seed_scores.index.get_level_values('policy_background')]\n",
    "average_scores = equal_background_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': 'mean', 'std_score': 'std'})\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_7897/790856185.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  median_scores = equal_background_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': 'median', 'std_score': 'std'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_score</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>multicolor</th>\n",
       "      <th>multicolor</th>\n",
       "      <td>843.678802</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean_score  std_score\n",
       "encoder_background policy_background                       \n",
       "multicolor         multicolor         843.678802        0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_scores = equal_background_scores.groupby(['encoder_background', 'policy_background']).agg({'mean_score': 'median', 'std_score': 'std'})\n",
    "median_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get maximum scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qk/b7b3_k9j55jd9gm10z0chm3m0000gn/T/ipykernel_7897/128057864.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  idxmax_list = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])].groupby(['encoder_background']).agg({'score': ['max', 'mean', 'std', 'idxmax']})['score']['idxmax'].tolist()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder_background</th>\n",
       "      <th>policy_background</th>\n",
       "      <th>encoder_seed</th>\n",
       "      <th>policy_seed</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>multicolor</td>\n",
       "      <td>multicolor</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>878.161255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoder_background policy_background  encoder_seed  policy_seed       score\n",
       "60         multicolor        multicolor             4            4  878.161255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save idxmax to a list\n",
    "idxmax_list = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])].groupby(['encoder_background']).agg({'score': ['max', 'mean', 'std', 'idxmax']})['score']['idxmax'].tolist()\n",
    "print(idxmax_list)\n",
    "# select encoder_background, policy_background, seeds from the list\n",
    "selection = df.iloc[idxmax_list][['encoder_background', 'policy_background', 'encoder_seed', 'policy_seed', 'score']]\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'experiments/stitching_tests/CarRacing-v2-multicolor/rgb/translate/fps/CarRacing-v2_relu_stitching_results_ppo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     stitch_filename \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manchoring_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m stitch_filename \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_id_encoder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_activation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_stitching_results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_algo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m df_transl \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstitch_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/projects/rl_relrepr_gymnasium/.venv/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'experiments/stitching_tests/CarRacing-v2-multicolor/rgb/translate/fps/CarRacing-v2_relu_stitching_results_ppo.csv'"
     ]
    }
   ],
   "source": [
    "stitching_method = stitching_methods[2]\n",
    "anchoring_method = \"fps\"\n",
    "\n",
    "model_activation = \"relu\"\n",
    "model_algo = \"ppo\"\n",
    "\n",
    "stitch_filename = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename += f\"{anchoring_method}/\"\n",
    "stitch_filename += f\"{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "\n",
    "df_transl = pd.read_csv(stitch_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all the cells where encoder_seed == selection.encoder_seed and policy_seed == selection.policy_seed, for each row in selection\n",
    "selection1 = df_transl[(df_transl['encoder_seed'] == selection.iloc[0]['encoder_seed']) & (df_transl['policy_seed'] == selection.iloc[0]['policy_seed'])]\n",
    "selection2 = df_transl[(df_transl['encoder_seed'] == selection.iloc[1]['encoder_seed']) & (df_transl['policy_seed'] == selection.iloc[1]['policy_seed'])]\n",
    "selection3 = df_transl[(df_transl['encoder_seed'] == selection.iloc[2]['encoder_seed']) & (df_transl['policy_seed'] == selection.iloc[2]['policy_seed'])]\n",
    "selection4 = df_transl[(df_transl['encoder_seed'] == selection.iloc[3]['encoder_seed']) & (df_transl['policy_seed'] == selection.iloc[3]['policy_seed'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CarRacing multicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "background = \"multicolor\"\n",
    "env_id_encoder = \"CarRacing-v2-multicolor\"\n",
    "env_id = \"CarRacing-v2\"\n",
    "encoder_order = ['multicolor'] if env_id_encoder.startswith(\"CarRacing-v2\") else ['plain', 'green', 'red']\n",
    "controller_order = ['green', 'red', 'blue'] if env_id_encoder.startswith(\"CarRacing-v2\") else ['plain', 'green', 'red']\n",
    "stitching_methods = [\"absolute\", \"relative\", \"translate\"]\n",
    "stitching_method = stitching_methods[0]\n",
    "anchoring_method = \"fps\"\n",
    "anchors_alpha = 0.999\n",
    "\n",
    "a_alpha = str(anchors_alpha)\n",
    "\n",
    "model_activation = \"relu\"\n",
    "model_algo = \"ppo\"\n",
    "\n",
    "\n",
    "stitch_filename = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename += f\"{anchoring_method}/\"\n",
    "if stitching_method == \"relative\":\n",
    "    stitch_filename += f\"a_{a_alpha}/\"\n",
    "# stitch_filename += f\"{background}-bg_{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "stitch_filename += f\"{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "\n",
    "df = pd.read_csv(stitch_filename)\n",
    "\n",
    "# Convert 'encoder_background' to categorical with specified order\n",
    "df['encoder_background'] = pd.Categorical(df['encoder_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# Convert 'policy_background' to categorical with specified order\n",
    "df['policy_background'] = pd.Categorical(df['policy_background'], categories=controller_order, ordered=True)\n",
    "\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std']})\n",
    "# show another column \"score\" next to max_score columnm containing the mean and std of the score\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std'], 'score': ['mean', 'std']})\n",
    "\n",
    "df.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results when encoder_seed and policy_seed are the same\n",
    "print('Same encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] == df['policy_seed'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] == df['policy_seed'])]['score'].std())\n",
    "\n",
    "# print results when encoder_seed and policy_seed are different\n",
    "print('Different encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] != df['policy_seed'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] != df['policy_seed'])]['score'].std())\n",
    "\n",
    "# print cumulative results\n",
    "print('Cumulative scores')\n",
    "print(df['score'].mean())\n",
    "print(df['score'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "env_id = \"BoxingNoFrameskip-v4\"\n",
    "env_id_encoder = \"BoxingNoFrameskip-v4\"\n",
    "encoder_order = ['plain', 'green', 'red']\n",
    "stitching_methods = [\"absolute\", \"relative\", \"translate\"]\n",
    "stitching_method = stitching_methods[2]\n",
    "anchoring_method = \"fps\"\n",
    "\n",
    "anchors_alpha = 0.999\n",
    "\n",
    "a_alpha = str(anchors_alpha)\n",
    "\n",
    "model_activation = \"relu\"\n",
    "model_algo = \"ppo\"\n",
    "\n",
    "stitch_filename = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename += f\"{anchoring_method}/\"\n",
    "if stitching_method == \"relative\":\n",
    "    stitch_filename += f\"a_{a_alpha}/\"\n",
    "stitch_filename += f\"{env_id_encoder}_{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "\n",
    "df = pd.read_csv(stitch_filename)\n",
    "\n",
    "# Convert 'encoder_background' to categorical with specified order\n",
    "df['encoder_background'] = pd.Categorical(df['encoder_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# Convert 'policy_background' to categorical with specified order\n",
    "df['policy_background'] = pd.Categorical(df['policy_background'], categories=encoder_order, ordered=True)\n",
    "\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std']})\n",
    "# show another column \"score\" next to max_score columnm containing the mean and std of the score\n",
    "# df.groupby(['encoder_background', 'policy_background']).agg({'max_score_reached': ['mean', 'std'], 'score': ['mean', 'std']})\n",
    "\n",
    "df.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the dataframe where encoder_background == policy_background and encoder_background == 'plain'. Show the score, encoder_seed and policy_seed\n",
    "df[(df['policy_background'] == 'plain') & (df['encoder_background'] == 'plain')][['score', 'encoder_background', 'policy_background', 'encoder_seed', 'policy_seed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the total number of rows\n",
    "print(f\"Total number of rows: {df.shape[0]}\")\n",
    "\n",
    "# get scores for when encoder_seed == policy_seed and encoder_background == policy_background\n",
    "print('Same encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].std())\n",
    "\n",
    "# show the mean score of all the experiments where encoder_background == policy_background\n",
    "# compute the mean score\n",
    "print('Same encoder and policy background')\n",
    "print(df[df['encoder_background'] == df['policy_background']]['score'].mean())\n",
    "print(df[df['encoder_background'] == df['policy_background']]['score'].std())\n",
    "print()\n",
    "# show the mean score of all the experiments, excluding where encoder_background == policy_background\n",
    "# compute the mean score\n",
    "print('Different encoder and policy background')\n",
    "print(df[df['encoder_background'] != df['policy_background']]['score'].mean())\n",
    "print(df[df['encoder_background'] != df['policy_background']]['score'].std())\n",
    "\n",
    "print('Cumulative scores')\n",
    "print(df['score'].mean())\n",
    "print(df['score'].std())\n",
    "\n",
    "# get scores for when encoder_seed == policy_seed and encoder_background == policy_background\n",
    "print('Same encoder and policy seed')\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].mean())\n",
    "print(df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]['score'].std())\n",
    "\n",
    "# get all the rows where encoder_seed == policy_seed and encoder_background == policy_background\n",
    "equal_seed = df[(df['encoder_seed'] == df['policy_seed']) & (df['encoder_background'] == df['policy_background'])]\n",
    "# compute mean score over colors, show mean and std, encoder_seed and policy_seed, encoder_background and policy_background only for values that are the not nan\n",
    "equal_seed_scores = equal_seed.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
    "equal_seed_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When encoder seed and policy seed are different, or when the encoder and policy background are different (in which case we do not care whether the seed is the same or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the rows where encoder_seed != policy_seed or encoder_background != policy_background\n",
    "diff = df[(df['encoder_seed'] != df['policy_seed']) | (df['encoder_background'] != df['policy_background'])]\n",
    "# compute aggregate score over environment seeds, show mean and std, encoder_seed and policy_seed, encoder_background and policy_background only for values that are the not nan\n",
    "diff_scores = diff.groupby(['encoder_background', 'policy_background']).agg({'score': ['mean', 'std']}).dropna()\n",
    "diff_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CarRacing-v2\"\n",
    "env_info = \"rgb\"\n",
    "anchoring_method = \"fps\"\n",
    "\n",
    "\"\"\" SHOW LOGGED DATA \"\"\"\n",
    "\n",
    "# read stitching_results_relative_ppo with pandas\n",
    "df1 = pd.read_csv(f'{test_path}/{env_id}/{env_info}/absolute/relu_stitching_results_ppo.csv', sep=',')\n",
    "df1.head()\n",
    "stitch_filename_2 = f\"experiments/stitching_tests/{env_id}/{env_info}/{stitching_method}/\"\n",
    "if stitching_method == \"translate\":\n",
    "    stitch_filename_2 += f\"{anchoring_method}/\"\n",
    "stitch_filename_2 += f\"{model_activation}_stitching_results_{model_algo}.csv\"\n",
    "# df2 = pd.read_csv(f'{test_path}/{env_id}/{env_info}/translate/relu_stitching_results_ppo.csv', sep=',')\n",
    "df2 = pd.read_csv(stitch_filename_2)\n",
    "\n",
    "\n",
    "\n",
    "# join the two dataframes adding a new column called \"method\". Use \"absolute\" under method for df1 and \"translate\" for df2\n",
    "df1['method'] = 'absolute'\n",
    "# sum 40 to df1 env_seed column\n",
    "df1['env_seed'] = df1['env_seed'] + 39\n",
    "df2['method'] = 'translate'\n",
    "\n",
    "# create df3 containing data where encoder_background and policy_background are the same, and remove it from df1 and df2\n",
    "df3 = df1[df1['encoder_background'] == df1['policy_background']]\n",
    "df3['method'] = 'absolute_original'\n",
    "df1 = df1[df1['encoder_background'] != df1['policy_background']]\n",
    "df4 = df2[df2['encoder_background'] == df2['policy_background']]\n",
    "df4['method'] = 'translate_original'\n",
    "df2 = df2[df2['encoder_background'] != df2['policy_background']]\n",
    "\n",
    "# concatenate the four dataframes\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\"\"\" df contains the following columns: env_seed\tencoder_background\tpolicy_background\tscore\tmax_score_reached\tepisode_length\talgorithm\n",
    "Create a histogram with x axis being the env_seed and y axis being the score. Use \"absolute\" and \"translation\" as colors.\n",
    "Each score must be a bar.\n",
    "\"\"\"\n",
    "fig = px.box(df, x=\"env_seed\", y=\"score\", color=\"method\", facet_row=\"encoder_background\", height=800)\n",
    "#fig = px.histogram(df, x=\"env_seed\", y=\"score\", color=\"method\", barmode=\"group\", histfunc=\"avg\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Allora puoi fare un istrogramma con plotly express. Prendi in input il df e metti come x il track_seed,\n",
    "come y il valore di score raggiunto o quello che è, come color il metodo usato (che sarà o absolute o translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
